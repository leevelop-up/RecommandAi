"""
AI ë‹µë³€ ì „ìš© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
----------------------------------------------
ìž…ë ¥:  output/scrap/  (ìŠ¤í¬ëž© ê²°ê³¼ 4íŒŒì¼)
ì¶œë ¥:  output/ai/     (AI ë¶„ì„ ê²°ê³¼)

ì‹¤í–‰:
    python Aidata/run_aidata.py

ìŠ¤í¬ëž©ì„ ë¨¼ì € ì‹¤í–‰í•´ì•¼ í•¨:
    python scrapers/run_scrapers.py   â† Step 1
    python Aidata/run_aidata.py       â† Step 2
"""
import sys
import os
import json
from datetime import datetime
from pathlib import Path
from typing import Dict

ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, ROOT_DIR)

from loguru import logger

from config.settings import get_settings
from processors.gemini_client import GeminiClient
from processors.groq_client   import GroqClient

SCRAP_DIR  = Path(ROOT_DIR) / "output" / "scrap"
AI_OUT_DIR = Path(ROOT_DIR) / "output" / "ai"

# â”€â”€ ìŠ¤í¬ëž© íŒŒì¼ ë§¤í•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_SCRAP_FILES = {
    "news":            "news_summary.json",
    "stocks":          "rising_stocks.json",
    "themes":          "rising_themes.json",
    "company_details": "company_details.json",
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_scrap_data() -> Dict:
    """output/scrap/ 4íŒŒì¼ ë¡œë“œ"""
    data: Dict[str, dict] = {}
    for key, filename in _SCRAP_FILES.items():
        path = SCRAP_DIR / filename
        if path.exists():
            with open(path, "r", encoding="utf-8") as f:
                data[key] = json.load(f)
            logger.info(f"  âœ… {filename} ë¡œë“œ")
        else:
            logger.warning(f"  âš ï¸  {filename} ì—†ìŒ â€” ìŠ¤í¬ëž©ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”")
            data[key] = {}
    return data


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í”„ë¡¬í”„íŠ¸ ë¹Œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_prompt(data: Dict, engine_name: str) -> str:
    """ìŠ¤í¬ëž© ê²°ê³¼ 4íŒŒì¼ â†’ AI í”„ë¡¬í”„íŠ¸"""
    lines = [
        f"# {engine_name} AI â€” ê¸ˆì£¼ ì£¼ì‹ ì¶”ì²œ ë¶„ì„\n",
        "ì•„ëž˜ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ ê¸ˆì£¼ íˆ¬ìž ì „ëžµì„ ì œì‹œí•˜ì„¸ìš”.\n",
    ]

    stocks_data  = data.get("stocks",          {})
    themes_data  = data.get("themes",          {})
    news_data    = data.get("news",            {})
    details_data = data.get("company_details", {})

    # â”€â”€ 1. ì‹œìž¥ í˜„í™© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    market = stocks_data.get("market_overview", {})
    lines.append("## 1. ì‹œìž¥ í˜„í™©")

    lines.append("\n### í•œêµ­ ì‹œìž¥")
    korea_market = market.get("korea", {})
    if korea_market:
        for name, info in korea_market.items():
            if isinstance(info, dict):
                lines.append(f"- {name}: {info.get('value', 'N/A')} ({info.get('change_rate', 'N/A')}%)")
            else:
                lines.append(f"- {name}: {info}")
    else:
        lines.append("- ë°ì´í„° ì—†ìŒ")

    lines.append("\n### ë¯¸êµ­ ì‹œìž¥")
    usa_market = market.get("usa", {})
    if usa_market:
        for name, info in usa_market.items():
            if isinstance(info, dict):
                lines.append(f"- {name}: {info.get('price', 'N/A')} ({info.get('change_percent', 'N/A')}%)")
            else:
                lines.append(f"- {name}: {info}")
    else:
        lines.append("- ë°ì´í„° ì—†ìŒ")

    # â”€â”€ 2. Hot í…Œë§ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    themes = themes_data.get("themes", [])
    if themes:
        lines.append("\n## 2. Hot í…Œë§ˆ")
        for theme in themes[:10]:
            lines.append(
                f"\n### {theme['rank']}. {theme['name']}  "
                f"(ì ìˆ˜ {theme['score']}/100, ë“±ë½ë¥  {theme['change_rate']})"
            )
            # 1ì°¨Â·2ì°¨Â·3ì°¨ ê´€ë ¨ì£¼
            for tier_key, label in [("tier1_stocks", "1ì°¨"), ("tier2_stocks", "2ì°¨"), ("tier3_stocks", "3ì°¨")]:
                tier_stocks = theme.get(tier_key, [])
                if tier_stocks:
                    names = [
                        f"{s.get('name', '')}({s.get('change_rate', '')})"
                        for s in tier_stocks[:5]
                    ]
                    lines.append(f"- {label} ê´€ë ¨ì£¼: {', '.join(names)}")

            # í…Œë§ˆ ê´€ë ¨ ë‰´ìŠ¤
            for n in theme.get("news", [])[:3]:
                lines.append(f"  Â· {n.get('title', '')[:60]}")

    # â”€â”€ 3. ìƒìŠ¹ ì¢…ëª© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    kr_stocks = stocks_data.get("korea_stocks", [])
    us_stocks = stocks_data.get("usa_stocks",   [])
    all_stocks = kr_stocks + us_stocks

    if all_stocks:
        lines.append(f"\n## 3. ìƒìŠ¹ ì¢…ëª© ({len(all_stocks)}ê°œ)")
        for s in all_stocks[:30]:
            country = s.get("country", "KR")
            cur     = "ì›" if country == "KR" else "USD"
            price   = s.get("current_price", 0)
            try:
                price_fmt = f"{price:,}"
            except (TypeError, ValueError):
                price_fmt = str(price)

            lines.append(f"\n### {s.get('name', '')} ({s.get('ticker', '')}) [{country}]")
            lines.append(f"- í˜„ìž¬ê°€: {price_fmt}{cur}, ë“±ë½ë¥ : {s.get('change_rate', '0%')}")
            lines.append(
                f"- PER: {s.get('per', 'N/A')}, "
                f"PBR: {s.get('pbr', 'N/A')}, "
                f"ì‹œê°€ì´ì•¡: {s.get('market_cap', 'N/A')}"
            )
            if s.get("sector"):
                lines.append(f"- ì„¹í„°: {s['sector']}")
            for n in s.get("news", [])[:2]:
                lines.append(f"  Â· {n.get('title', '')[:50]}")

    # â”€â”€ 4. í…Œë§ˆë³„ ê´€ë ¨ì£¼ ì„¸ë¶€ ì •ë³´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    companies = details_data.get("companies", {})
    # í…Œë§ˆë³„ë¡œ ê·¸ë£¹í™”
    theme_map: Dict[str, list] = {}
    for ticker, info in companies.items():
        for tn in info.get("themes", []):
            theme_map.setdefault(tn, []).append(info)

    if theme_map:
        lines.append("\n## 4. í…Œë§ˆë³„ ê´€ë ¨ì£¼ ì„¸ë¶€ ì •ë³´")
        for tn, t_stocks in theme_map.items():
            lines.append(f"\n### {tn}")
            for s in t_stocks[:8]:
                lines.append(
                    f"- {s.get('name', '')}({s.get('ticker', '')}): "
                    f"ê°€ê²© {s.get('current_price', 0)}, "
                    f"PER {s.get('per', 'N/A')}, "
                    f"ì„¹í„° {s.get('sector', 'N/A')}"
                )

    # â”€â”€ 5. ì‹œìž¥ ë‰´ìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    articles = news_data.get("articles", [])
    if articles:
        lines.append(f"\n## 5. ì£¼ìš” ì‹œìž¥ ë‰´ìŠ¤ (ì´ {len(articles)}ê°œ ì¤‘ ìƒìœ„ 20)")
        for i, a in enumerate(articles[:20], 1):
            src = a.get("_source", "")
            lines.append(f"{i}. [{src}] {a.get('title', '')[:70]}")

    # â”€â”€ ì‘ë‹µ í˜•ì‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    lines.append("""
## ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ ì´ JSON êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”)

```json
{
  "market_analysis": {
    "overall_sentiment": "ë§¤ìš° ê¸ì •ì  | ê¸ì •ì  | ì¤‘ë¦½ | ë¶€ì •ì  | ë§¤ìš° ë¶€ì •ì ",
    "korea_outlook": "í•œêµ­ ì‹œìž¥ ì „ë§ (2-3ë¬¸ìž¥)",
    "usa_outlook": "ë¯¸êµ­ ì‹œìž¥ ì „ë§ (2-3ë¬¸ìž¥)",
    "key_trends": ["íŠ¸ë Œë“œ1", "íŠ¸ë Œë“œ2", "íŠ¸ë Œë“œ3"],
    "risks": ["ë¦¬ìŠ¤í¬1", "ë¦¬ìŠ¤í¬2"]
  },
  "top_themes_analysis": [
    {
      "theme": "í…Œë§ˆëª…",
      "rating": "ë§¤ìš° ê°•ì„¸ | ê°•ì„¸ | ë³´í†µ | ì•½ì„¸",
      "reasoning": "ë¶„ì„ ê·¼ê±° (2-3ë¬¸ìž¥)",
      "recommended_stocks": ["ì¢…ëª©1", "ì¢…ëª©2", "ì¢…ëª©3"]
    }
  ],
  "top_10_picks": [
    {
      "rank": 1,
      "ticker": "ì¢…ëª©ì½”ë“œ",
      "name": "ì¢…ëª©ëª…",
      "country": "KR | US",
      "action": "ì ê·¹ë§¤ìˆ˜ | ë§¤ìˆ˜ | ë³´ìœ ",
      "target_return": "10-15%",
      "reasoning": "ì¶”ì²œ ê·¼ê±° (3-4ë¬¸ìž¥)",
      "entry_price": "ì¶”ì²œ ë§¤ìˆ˜ê°€",
      "target_price": "ëª©í‘œê°€",
      "stop_loss": "ì†ì ˆê°€",
      "investment_period": "ë‹¨ê¸°(1ê°œì›”) | ì¤‘ê¸°(3ê°œì›”) | ìž¥ê¸°(6ê°œì›”+)"
    }
  ],
  "sector_recommendations": [
    {
      "sector": "ì„¹í„°ëª…",
      "rating": "ë¹„ì¤‘í™•ëŒ€ | ì¤‘ë¦½ | ë¹„ì¤‘ì¶•ì†Œ",
      "reasoning": "ê·¼ê±° (2ë¬¸ìž¥)"
    }
  ],
  "risk_warning": "ì „ì²´ ì‹œìž¥ ìœ„í—˜ ìš”ì†Œ (3-4ë¬¸ìž¥)",
  "investment_strategy": "ì´ë²ˆ ì£¼ íˆ¬ìž ì „ëžµ ìš”ì•½ (4-5ë¬¸ìž¥)"
}
```

ì¤‘ìš”:
1. ëª¨ë“  ë¶„ì„ì€ ì œê³µëœ ì‹¤ì œ ë°ì´í„°ì™€ ë‰´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì„¸ìš”
2. êµ¬ì²´ì ì¸ ìˆ«ìžì™€ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”
3. ê¸ì •ì /ë¶€ì •ì  ì¸¡ë©´ì„ ê· í˜•ìžˆê²Œ ë‹¤ë£¨ì„¸ìš”
4. íˆ¬ìž ìœ„í—˜ì„ ëª…í™•ížˆ ì–¸ê¸‰í•˜ì„¸ìš”
5. top_10_picksëŠ” ë°˜ë“œì‹œ 10ê°œë¥¼ ì„ ì •í•˜ì„¸ìš”
""")

    return "\n".join(lines)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AI ë¶„ì„ (Gemini + Groq ë“€ì–¼)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_SYSTEM_INSTRUCTION = """ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ì „ë¬¸ ì£¼ì‹ ì• ë„ë¦¬ìŠ¤íŠ¸ìž…ë‹ˆë‹¤.
- í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
- ë°ì´í„°ì™€ ë‰´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
- íˆ¬ìž ìœ„í—˜ê³¼ ê¸°íšŒë¥¼ ê· í˜•ìžˆê²Œ ì œì‹œí•˜ì„¸ìš”.
- JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."""


def run_ai_analysis(data: Dict) -> Dict:
    """Gemini + Groq ë“€ì–¼ ë¶„ì„"""
    settings = get_settings()
    result: Dict = {
        "generated_at":       datetime.now().isoformat(),
        "ai_recommendations": {},
    }

    # â”€â”€ Gemini â”€â”€
    gemini_key = settings.GEMINI_API_KEY
    if gemini_key and gemini_key != "your-gemini-api-key":
        logger.info("[1/2] Gemini AI ë¶„ì„ ì¤‘...")
        try:
            gemini = GeminiClient(api_key=gemini_key)
            prompt = build_prompt(data, "Gemini")
            gemini_result = gemini.generate_json(
                prompt,
                system_instruction=_SYSTEM_INSTRUCTION,
                temperature=0.3,
            )
            if gemini_result:
                gemini_result["engine"]      = "gemini"
                gemini_result["analyzed_at"] = datetime.now().isoformat()
                result["ai_recommendations"]["gemini"] = gemini_result
                logger.info("  âœ… Gemini ë¶„ì„ ì™„ë£Œ")
            else:
                logger.warning("  âŒ Gemini ì‘ë‹µ ë¹„ì–´ìžˆìŒ")
        except Exception as e:
            logger.error(f"  âŒ Gemini ì˜¤ë¥˜: {e}")
    else:
        logger.warning("[1/2] Gemini API í‚¤ ë¯¸ì„¤ì • â€” ê±´ë„ˆëœ€")

    # â”€â”€ Groq â”€â”€
    groq_key = settings.GROQ_API_KEY
    if groq_key and groq_key != "your-groq-api-key":
        logger.info("[2/2] Groq AI ë¶„ì„ ì¤‘...")
        try:
            groq = GroqClient(api_key=groq_key)
            if groq.is_available():
                prompt = build_prompt(data, "Groq")
                groq_result = groq.generate_json(
                    prompt,
                    system_instruction=_SYSTEM_INSTRUCTION,
                    temperature=0.3,
                )
                if groq_result:
                    groq_result["engine"]      = "groq"
                    groq_result["analyzed_at"] = datetime.now().isoformat()
                    result["ai_recommendations"]["groq"] = groq_result
                    logger.info("  âœ… Groq ë¶„ì„ ì™„ë£Œ")
                else:
                    logger.warning("  âŒ Groq ì‘ë‹µ ë¹„ì–´ìžˆìŒ")
            else:
                logger.warning("  âŒ Groq í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨ (íŒ¨í‚¤ì§€ or í‚¤ ë¬¸ì œ)")
        except Exception as e:
            logger.error(f"  âŒ Groq ì˜¤ë¥˜: {e}")
    else:
        logger.warning("[2/2] Groq API í‚¤ ë¯¸ì„¤ì • â€” ê±´ë„ˆëœ€")

    if not result["ai_recommendations"]:
        logger.error("âŒ ëª¨ë“  AI ë¶„ì„ ì‹¤íŒ¨ â€” API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”")

    return result


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²°ê³¼ ì €ìž¥
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def save_ai_result(result: Dict) -> Path:
    """output/ai/ ì €ìž¥"""
    AI_OUT_DIR.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    path      = AI_OUT_DIR / f"weekly_recommendation_{timestamp}.json"

    with open(path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    logger.info(f"  âœ… {path} ì €ìž¥")
    return path


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¡œê±° ì„¤ì • + main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def setup_logger():
    logger.remove()
    log_dir = Path(ROOT_DIR) / "logs"
    log_dir.mkdir(exist_ok=True)
    logger.add(
        sys.stderr, level="INFO",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level:<7} | {message}",
    )
    logger.add(
        str(log_dir / "aidata_{time:YYYYMMDD}.log"),
        level="DEBUG", rotation="1 day", retention="30 days",
    )


if __name__ == "__main__":
    setup_logger()

    logger.info("=" * 70)
    logger.info("  AI ë¶„ì„ ì‹œìž‘  â†’  output/ai/")
    logger.info("=" * 70)

    logger.info("\nðŸ“‚ ìŠ¤í¬ëž© ë°ì´í„° ë¡œë“œ...")
    data = load_scrap_data()

    logger.info("\nðŸ¤– AI ë¶„ì„...")
    result = run_ai_analysis(data)

    logger.info("\nðŸ’¾ ê²°ê³¼ ì €ìž¥...")
    save_ai_result(result)

    logger.info("\n" + "=" * 70)
    logger.info("  AI ë¶„ì„ ì™„ë£Œ")
    logger.info("=" * 70)
