"""
ë™ì  í…Œë§ˆ/ê´€ë ¨ì£¼ ìŠ¤í¬ë˜í¼
ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ í…Œë§ˆ ë° ê´€ë ¨ì£¼ë¥¼ ìˆ˜ì§‘ (í•˜ë“œì½”ë”© ì—†ìŒ)
"""
import requests
from bs4 import BeautifulSoup
from typing import Dict, List, Optional, Tuple
from loguru import logger
import time
import re
from collections import defaultdict


class DynamicThemeScraper:
    """ë™ì  í…Œë§ˆ/ê´€ë ¨ì£¼ ìŠ¤í¬ë˜í¼ - í•˜ë“œì½”ë”© ì—†ì´ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘"""

    BASE_URL = "https://finance.naver.com"
    HEADERS = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
    }

    def __init__(self, delay: float = 0.3):
        self.delay = delay
        self.session = requests.Session()
        self.session.headers.update(self.HEADERS)
        self._theme_cache = {}  # í…Œë§ˆ ëª©ë¡ ìºì‹œ
        self._stock_themes = defaultdict(list)  # ì¢…ëª©ë³„ ì†Œì† í…Œë§ˆ

    def _get_soup(self, url: str) -> Optional[BeautifulSoup]:
        """URLì—ì„œ BeautifulSoup ê°ì²´ ë°˜í™˜"""
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            time.sleep(self.delay)
            return BeautifulSoup(response.text, "html.parser")
        except Exception as e:
            logger.error(f"í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {url}, {e}")
            return None

    def get_all_themes(self, pages: int = None, max_pages: int = 50) -> List[Dict]:
        """
        ì „ì²´ í…Œë§ˆ ëª©ë¡ ì¡°íšŒ (ì—¬ëŸ¬ í˜ì´ì§€)

        Args:
            pages: ì¡°íšŒí•  í˜ì´ì§€ ìˆ˜ (Noneì´ë©´ ìë™ìœ¼ë¡œ ëª¨ë“  í˜ì´ì§€ í¬ë¡¤ë§)
            max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜ ì œí•œ (ë¬´í•œ ë£¨í”„ ë°©ì§€)

        Returns:
            í…Œë§ˆ ëª©ë¡
        """
        all_themes = []
        page = 1

        # pagesê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ìë™ìœ¼ë¡œ ëª¨ë“  í˜ì´ì§€ í¬ë¡¤ë§
        if pages is None:
            logger.info("ëª¨ë“  í…Œë§ˆ í˜ì´ì§€ ìë™ í¬ë¡¤ë§ ì‹œì‘...")
            while page <= max_pages:
                url = f"{self.BASE_URL}/sise/theme.naver?&page={page}"
                soup = self._get_soup(url)

                if not soup:
                    break

                try:
                    links = soup.select('td a[href*="type=theme"]')

                    # ë” ì´ìƒ í…Œë§ˆê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                    if not links:
                        logger.info(f"í˜ì´ì§€ {page}ì—ì„œ í…Œë§ˆ ì—†ìŒ - í¬ë¡¤ë§ ì¢…ë£Œ")
                        break

                    page_themes = []
                    for link in links:
                        href = link.get("href", "")
                        code_match = re.search(r"no=(\d+)", href)
                        if code_match:
                            theme_name = link.text.strip()
                            theme_code = code_match.group(1)

                            # ë“±ë½ë¥  ì°¾ê¸°
                            parent_td = link.find_parent("td")
                            if parent_td:
                                next_tds = parent_td.find_next_siblings("td")
                                change_rate = next_tds[1].text.strip() if len(next_tds) > 1 else ""
                            else:
                                change_rate = ""

                            page_themes.append({
                                "name": theme_name,
                                "code": theme_code,
                                "change_rate": change_rate,
                            })

                    if page_themes:
                        all_themes.extend(page_themes)
                        logger.info(f"í˜ì´ì§€ {page}: {len(page_themes)}ê°œ í…Œë§ˆ ìˆ˜ì§‘ (ëˆ„ì : {len(all_themes)}ê°œ)")
                    else:
                        break

                    page += 1

                except Exception as e:
                    logger.error(f"í…Œë§ˆ ëª©ë¡ íŒŒì‹± ì‹¤íŒ¨ (page {page}): {e}")
                    break
        else:
            # ì§€ì •ëœ í˜ì´ì§€ ìˆ˜ë§Œí¼ë§Œ í¬ë¡¤ë§
            for page in range(1, pages + 1):
                url = f"{self.BASE_URL}/sise/theme.naver?&page={page}"
                soup = self._get_soup(url)

                if not soup:
                    continue

                try:
                    links = soup.select('td a[href*="type=theme"]')
                    for link in links:
                        href = link.get("href", "")
                        code_match = re.search(r"no=(\d+)", href)
                        if code_match:
                            theme_name = link.text.strip()
                            theme_code = code_match.group(1)

                            # ë“±ë½ë¥  ì°¾ê¸°
                            parent_td = link.find_parent("td")
                            if parent_td:
                                next_tds = parent_td.find_next_siblings("td")
                                change_rate = next_tds[1].text.strip() if len(next_tds) > 1 else ""
                            else:
                                change_rate = ""

                            all_themes.append({
                                "name": theme_name,
                                "code": theme_code,
                                "change_rate": change_rate,
                            })

                except Exception as e:
                    logger.error(f"í…Œë§ˆ ëª©ë¡ íŒŒì‹± ì‹¤íŒ¨ (page {page}): {e}")

        # ìºì‹œì— ì €ì¥
        for theme in all_themes:
            self._theme_cache[theme["name"]] = theme["code"]
            self._theme_cache[theme["code"]] = theme["name"]

        logger.info(f"ì „ì²´ í…Œë§ˆ ì¡°íšŒ ì™„ë£Œ: {len(all_themes)}ê°œ")
        return all_themes

    def get_theme_stocks(self, theme_code: str) -> List[Dict]:
        """
        íŠ¹ì • í…Œë§ˆì˜ ì¢…ëª© ì¡°íšŒ

        Args:
            theme_code: í…Œë§ˆ ì½”ë“œ

        Returns:
            ì¢…ëª© ë¦¬ìŠ¤íŠ¸
        """
        url = f"{self.BASE_URL}/sise/sise_group_detail.naver?type=theme&no={theme_code}"
        soup = self._get_soup(url)

        if not soup:
            return []

        stocks = []
        try:
            # í…Œë§ˆëª… ì¶”ì¶œ
            theme_name = ""
            title = soup.select_one(".sub_tlt")
            if title:
                theme_name = title.text.strip()

            # ì¢…ëª© í…Œì´ë¸”
            rows = soup.select("table.type_5 tbody tr")
            for row in rows:
                cols = row.select("td")
                if len(cols) >= 6:
                    link = cols[0].select_one("a")
                    if link:
                        href = link.get("href", "")
                        ticker_match = re.search(r"code=(\d+)", href)
                        if ticker_match:
                            ticker = ticker_match.group(1)
                            name = link.text.strip()

                            # í˜„ì¬ê°€
                            price_text = cols[1].text.strip().replace(",", "")
                            price = int(price_text) if price_text.isdigit() else 0

                            # ì „ì¼ë¹„
                            change_text = cols[2].text.strip().replace(",", "")

                            # ë“±ë½ë¥ 
                            rate_text = cols[3].text.strip()

                            stocks.append({
                                "ticker": ticker,
                                "name": name,
                                "price": price,
                                "change": change_text,
                                "change_rate": rate_text,
                                "theme": theme_name,
                            })

                            # ì¢…ëª©ë³„ í…Œë§ˆ ë§¤í•‘
                            self._stock_themes[ticker].append({
                                "code": theme_code,
                                "name": theme_name,
                            })

            logger.info(f"í…Œë§ˆ '{theme_name}' ì¢…ëª© ì¡°íšŒ ì™„ë£Œ: {len(stocks)}ê°œ")
            return stocks

        except Exception as e:
            logger.error(f"í…Œë§ˆ ì¢…ëª© íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []

    def search_theme(self, keyword: str) -> List[Dict]:
        """
        í‚¤ì›Œë“œë¡œ í…Œë§ˆ ê²€ìƒ‰

        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ

        Returns:
            ë§¤ì¹­ë˜ëŠ” í…Œë§ˆ ë¦¬ìŠ¤íŠ¸
        """
        # ìºì‹œê°€ ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´ í…Œë§ˆ ì¡°íšŒ
        if not self._theme_cache:
            self.get_all_themes()

        matched = []
        themes = self.get_all_themes(pages=10)

        for theme in themes:
            if keyword.lower() in theme["name"].lower():
                matched.append(theme)

        logger.info(f"í…Œë§ˆ ê²€ìƒ‰ '{keyword}': {len(matched)}ê°œ ë§¤ì¹­")
        return matched

    def get_stock_themes(self, ticker: str) -> List[Dict]:
        """
        íŠ¹ì • ì¢…ëª©ì´ ì†í•œ í…Œë§ˆ ì¡°íšŒ

        Args:
            ticker: ì¢…ëª© ì½”ë“œ

        Returns:
            í…Œë§ˆ ë¦¬ìŠ¤íŠ¸
        """
        url = f"{self.BASE_URL}/item/main.naver?code={ticker}"
        soup = self._get_soup(url)

        if not soup:
            return []

        themes = []
        try:
            # í…Œë§ˆ ì •ë³´ ì°¾ê¸° (ì¢…ëª© í˜ì´ì§€ì—ì„œ)
            theme_area = soup.select_one(".theme")
            if theme_area:
                theme_links = theme_area.select("a")
                for link in theme_links:
                    href = link.get("href", "")
                    code_match = re.search(r"no=(\d+)", href)
                    if code_match:
                        themes.append({
                            "name": link.text.strip(),
                            "code": code_match.group(1),
                        })

            # í…Œë§ˆë¥¼ ì°¾ì§€ ëª»í•˜ë©´ ì „ì²´ í…Œë§ˆì—ì„œ ê²€ìƒ‰
            if not themes:
                all_themes = self.get_all_themes(pages=3)
                for theme in all_themes[:30]:  # ìƒìœ„ 30ê°œ í…Œë§ˆë§Œ ê²€ìƒ‰
                    stocks = self.get_theme_stocks(theme["code"])
                    for stock in stocks:
                        if stock["ticker"] == ticker:
                            themes.append({
                                "name": theme["name"],
                                "code": theme["code"],
                            })
                            break

            logger.info(f"{ticker} ì†Œì† í…Œë§ˆ: {len(themes)}ê°œ")
            return themes

        except Exception as e:
            logger.error(f"ì¢…ëª© í…Œë§ˆ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def find_related_stocks(self, ticker: str, max_themes: int = 5) -> Dict:
        """
        ì¢…ëª©ì˜ ê´€ë ¨ì£¼ ì°¾ê¸° (ë™ì )
        í•´ë‹¹ ì¢…ëª©ì´ ì†í•œ í…Œë§ˆì˜ ë‹¤ë¥¸ ì¢…ëª©ë“¤ = ê´€ë ¨ì£¼

        Args:
            ticker: ì¢…ëª© ì½”ë“œ
            max_themes: ì¡°íšŒí•  ìµœëŒ€ í…Œë§ˆ ìˆ˜

        Returns:
            ê´€ë ¨ì£¼ ì •ë³´
        """
        # ì¢…ëª© ì´ë¦„ ì¡°íšŒ
        from scrapers.korea.naver_scraper import NaverFinanceScraper
        naver = NaverFinanceScraper(delay=0.2)
        stock_info = naver.get_realtime_price(ticker)
        stock_name = stock_info.get("name", ticker)

        # ì¢…ëª©ì´ ì†í•œ í…Œë§ˆ ì°¾ê¸°
        themes = self.get_stock_themes(ticker)

        if not themes:
            # í…Œë§ˆë¥¼ ì°¾ì§€ ëª»í•˜ë©´ ì¢…ëª©ëª…ìœ¼ë¡œ í…Œë§ˆ ê²€ìƒ‰
            matched_themes = self.search_theme(stock_name[:2])  # ì²« 2ê¸€ìë¡œ ê²€ìƒ‰
            themes = matched_themes[:max_themes]

        all_related = {}
        tier1 = []  # ê°™ì€ í…Œë§ˆì— ì—¬ëŸ¬ë²ˆ ë“±ì¥í•˜ëŠ” ì¢…ëª©
        tier2 = []  # ê°™ì€ í…Œë§ˆì— í•œë²ˆ ë“±ì¥í•˜ëŠ” ì¢…ëª©
        tier3 = []  # ì—°ê´€ í…Œë§ˆ ì¢…ëª©

        stock_count = defaultdict(int)

        # ê° í…Œë§ˆì˜ ì¢…ëª© ì¡°íšŒ
        for i, theme in enumerate(themes[:max_themes]):
            stocks = self.get_theme_stocks(theme["code"])

            for stock in stocks:
                if stock["ticker"] != ticker:  # ìê¸° ìì‹  ì œì™¸
                    stock_count[stock["ticker"]] += 1
                    all_related[stock["ticker"]] = {
                        **stock,
                        "themes": all_related.get(stock["ticker"], {}).get("themes", []) + [theme["name"]],
                    }

        # í‹°ì–´ ë¶„ë¥˜ (ë“±ì¥ íšŸìˆ˜ ê¸°ì¤€)
        for t, count in sorted(stock_count.items(), key=lambda x: -x[1]):
            stock_data = all_related[t]
            if count >= 3:
                tier1.append(stock_data)
            elif count >= 2:
                tier2.append(stock_data)
            else:
                tier3.append(stock_data)

        result = {
            "ticker": ticker,
            "name": stock_name,
            "themes": [t["name"] for t in themes],
            "tier1": tier1[:10],  # 1ì°¨ ê´€ë ¨ì£¼ (í•µì‹¬) - ìµœëŒ€ 10ê°œ
            "tier2": tier2[:15],  # 2ì°¨ ê´€ë ¨ì£¼ (ì£¼ìš”) - ìµœëŒ€ 15ê°œ
            "tier3": tier3[:20],  # 3ì°¨ ê´€ë ¨ì£¼ (ê¸°íƒ€) - ìµœëŒ€ 20ê°œ
            "total_related": len(all_related),
        }

        logger.info(f"{stock_name}({ticker}) ê´€ë ¨ì£¼ ì°¾ê¸° ì™„ë£Œ: 1ì°¨ {len(tier1)}, 2ì°¨ {len(tier2)}, 3ì°¨ {len(tier3)}")
        return result

    def find_theme_stocks_tiered(self, theme_keyword: str) -> Dict:
        """
        í…Œë§ˆ ê´€ë ¨ì£¼ ì°¾ê¸° (ê³„ì¸µë³„)

        Args:
            theme_keyword: í…Œë§ˆ í‚¤ì›Œë“œ

        Returns:
            ê³„ì¸µë³„ ê´€ë ¨ì£¼
        """
        # í…Œë§ˆ ê²€ìƒ‰
        matched_themes = self.search_theme(theme_keyword)

        if not matched_themes:
            logger.warning(f"í…Œë§ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {theme_keyword}")
            return {"theme": theme_keyword, "tier1": [], "tier2": [], "tier3": []}

        all_stocks = {}
        stock_count = defaultdict(int)

        # ë§¤ì¹­ëœ ëª¨ë“  í…Œë§ˆì˜ ì¢…ëª© ìˆ˜ì§‘
        for theme in matched_themes[:5]:  # ìµœëŒ€ 5ê°œ í…Œë§ˆ
            stocks = self.get_theme_stocks(theme["code"])
            for stock in stocks:
                stock_count[stock["ticker"]] += 1
                if stock["ticker"] not in all_stocks:
                    all_stocks[stock["ticker"]] = stock
                all_stocks[stock["ticker"]]["themes"] = all_stocks[stock["ticker"]].get("themes", []) + [theme["name"]]

        # ë“±ì¥ íšŸìˆ˜ ê¸°ì¤€ ì •ë ¬
        sorted_tickers = sorted(stock_count.keys(), key=lambda x: -stock_count[x])

        # ìƒìœ„ 30% = 1ì°¨, ì¤‘ê°„ 40% = 2ì°¨, ë‚˜ë¨¸ì§€ = 3ì°¨
        n = len(sorted_tickers)
        tier1_end = max(1, n // 3)
        tier2_end = max(2, 2 * n // 3)

        tier1 = [all_stocks[t] for t in sorted_tickers[:tier1_end]]
        tier2 = [all_stocks[t] for t in sorted_tickers[tier1_end:tier2_end]]
        tier3 = [all_stocks[t] for t in sorted_tickers[tier2_end:]]

        result = {
            "theme": theme_keyword,
            "matched_themes": [t["name"] for t in matched_themes],
            "tier1": tier1,
            "tier2": tier2,
            "tier3": tier3,
            "total": n,
        }

        logger.info(f"í…Œë§ˆ '{theme_keyword}' ê´€ë ¨ì£¼: 1ì°¨ {len(tier1)}, 2ì°¨ {len(tier2)}, 3ì°¨ {len(tier3)}")
        return result


def print_dynamic_related(data: Dict):
    """ë™ì  ê´€ë ¨ì£¼ ì¶œë ¥"""
    title = data.get("theme") or data.get("name") or data.get("ticker")
    print(f"\n{'='*70}")
    print(f"  ğŸ“Š [{title}] ê´€ë ¨ì£¼ ë¶„ì„ (ì‹¤ì‹œê°„)")
    print("="*70)

    if data.get("themes"):
        print(f"\nì†Œì† í…Œë§ˆ: {', '.join(data['themes'][:5])}")

    if data.get("matched_themes"):
        print(f"\në§¤ì¹­ í…Œë§ˆ: {', '.join(data['matched_themes'][:5])}")

    for tier_key, tier_label in [
        ("tier1", "ğŸ¥‡ 1ì°¨ ê´€ë ¨ì£¼ (í•µì‹¬)"),
        ("tier2", "ğŸ¥ˆ 2ì°¨ ê´€ë ¨ì£¼ (ì£¼ìš”)"),
        ("tier3", "ğŸ¥‰ 3ì°¨ ê´€ë ¨ì£¼ (ê¸°íƒ€)"),
    ]:
        stocks = data.get(tier_key, [])
        if stocks:
            print(f"\n{tier_label} ({len(stocks)}ê°œ)")
            print("-"*70)
            print(f"{'ì¢…ëª©':<12} {'í˜„ì¬ê°€':>12} {'ë“±ë½ë¥ ':>10} {'í…Œë§ˆ':>20}")
            print("-"*70)

            for stock in stocks[:10]:  # ê° tier ìµœëŒ€ 10ê°œ ì¶œë ¥
                name = stock.get("name", "")[:10]
                price = stock.get("price", 0)
                rate = stock.get("change_rate", "")
                themes = ", ".join(stock.get("themes", [])[:2])[:18]

                print(f"{name:<12} {price:>12,}ì› {rate:>10} {themes:>20}")


if __name__ == "__main__":
    scraper = DynamicThemeScraper()

    # 1. ì „ì²´ í…Œë§ˆ ëª©ë¡
    print("="*70)
    print("  ğŸ“‹ ì „ì²´ í…Œë§ˆ ëª©ë¡ (ìƒìœ„ 20ê°œ)")
    print("="*70)
    themes = scraper.get_all_themes(pages=2)
    for i, theme in enumerate(themes[:20], 1):
        print(f"  {i:2}. {theme['name']:<20} (ì½”ë“œ: {theme['code']}) {theme['change_rate']}")

    # 2. íŠ¹ì • í…Œë§ˆ ì¢…ëª©
    print("\n" + "="*70)
    print("  ğŸ”‹ 2ì°¨ì „ì§€ í…Œë§ˆ ì¢…ëª©")
    print("="*70)
    battery_themes = scraper.search_theme("2ì°¨ì „ì§€")
    if battery_themes:
        stocks = scraper.get_theme_stocks(battery_themes[0]["code"])
        for stock in stocks[:10]:
            print(f"  {stock['name']:<12} ({stock['ticker']}) | {stock['price']:>10,}ì› | {stock['change_rate']}")

    # 3. ì¢…ëª© ê´€ë ¨ì£¼ (ì‚¼ì„±ì „ì)
    print("\n" + "="*70)
    print("  ğŸ” ì‚¼ì„±ì „ì(005930) ê´€ë ¨ì£¼ ì°¾ê¸°")
    print("="*70)
    related = scraper.find_related_stocks("005930", max_themes=3)
    print_dynamic_related(related)
