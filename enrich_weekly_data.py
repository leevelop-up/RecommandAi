"""
Weekly Recommendation ë°ì´í„° ë³´ê°•
- í…Œë§ˆ ì¹´í…Œê³ ë¦¬ ë§¤í•‘
- ì‹¤ì‹œê°„ ì£¼ê°€ ë°ì´í„° ì¶”ê°€ (optional)
- RecommandStock í”„ë¡ íŠ¸ì—”ë“œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
"""
import json
from pathlib import Path
from datetime import datetime
from loguru import logger
from typing import Dict, List, Optional


def load_theme_categories() -> Dict[str, str]:
    """ìˆ˜ì§‘ëœ í…Œë§ˆ ì¹´í…Œê³ ë¦¬ ë¡œë“œ"""
    category_file = Path("data/theme_categories.json")

    if not category_file.exists():
        logger.warning(f"í…Œë§ˆ ì¹´í…Œê³ ë¦¬ íŒŒì¼ ì—†ìŒ: {category_file}")
        return {}

    with open(category_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # í…Œë§ˆëª… -> ì¹´í…Œê³ ë¦¬ ë§¤í•‘
    category_map = {}
    for theme in data.get("themes", []):
        theme_name = theme["name"]
        category = theme.get("category", "ê¸°íƒ€")
        theme_id = theme.get("id", "")

        category_map[theme_name] = {
            "id": theme_id,
            "category": category
        }

    logger.info(f"í…Œë§ˆ ì¹´í…Œê³ ë¦¬ {len(category_map)}ê°œ ë¡œë“œ")
    return category_map


def generate_theme_description(theme_name: str, news_count: int, change_rate: str) -> str:
    """í…Œë§ˆ ì„¤ëª… ìžë™ ìƒì„±"""
    descriptions = {
        "AI": "ì¸ê³µì§€ëŠ¥ ê´€ë ¨ ê¸°ìˆ  ë° ì„œë¹„ìŠ¤ê°€ ì£¼ëª©ë°›ê³  ìžˆëŠ” í…Œë§ˆìž…ë‹ˆë‹¤.",
        "ë°˜ë„ì²´": "ë°˜ë„ì²´ ì œì¡° ë° ìž¥ë¹„ ê´€ë ¨ ê¸°ì—…ë“¤ì˜ ì‹¤ì ì´ ê°œì„ ë˜ê³  ìžˆìŠµë‹ˆë‹¤.",
        "ì „ì§€": "2ì°¨ì „ì§€ ë° ë°°í„°ë¦¬ ì†Œìž¬ ê´€ë ¨ ìˆ˜ìš”ê°€ ì¦ê°€í•˜ê³  ìžˆìŠµë‹ˆë‹¤.",
        "ë°°í„°ë¦¬": "ì „ê¸°ì°¨ ë°°í„°ë¦¬ ê´€ë ¨ ê¸°ì—…ë“¤ì´ ì„±ìž¥í•˜ê³  ìžˆìŠµë‹ˆë‹¤.",
        "ë°©ì‚°": "ë°©ìœ„ì‚°ì—… ë° êµ­ë°© ê´€ë ¨ ìˆ˜ì£¼ê°€ ì¦ê°€í•˜ê³  ìžˆìŠµë‹ˆë‹¤.",
        "ìš°ì£¼": "ìš°ì£¼í•­ê³µì‚°ì—… ìœ¡ì„± ì •ì±…ìœ¼ë¡œ ê´€ë ¨ì£¼ê°€ ì£¼ëª©ë°›ê³  ìžˆìŠµë‹ˆë‹¤.",
        "ë°”ì´ì˜¤": "ë°”ì´ì˜¤ ì˜ì•½í’ˆ ê°œë°œ ì§„í–‰ìœ¼ë¡œ ê´€ì‹¬ì´ ë†’ì•„ì§€ê³  ìžˆìŠµë‹ˆë‹¤.",
        "ê²Œìž„": "ê²Œìž„ ì‚°ì—…ì˜ ì„±ìž¥ê³¼ í•¨ê»˜ ê´€ë ¨ì£¼ê°€ ì£¼ëª©ë°›ê³  ìžˆìŠµë‹ˆë‹¤.",
        "ê±´ì„¤": "ê±´ì„¤ ë° ë¶€ë™ì‚° ê´€ë ¨ ì •ì±…ìœ¼ë¡œ ê´€ì‹¬ì´ ì¦ê°€í•˜ê³  ìžˆìŠµë‹ˆë‹¤.",
    }

    base_desc = f"{theme_name} ê´€ë ¨ ì¢…ëª©ë“¤ì´ ì‹œìž¥ì˜ ê´€ì‹¬ì„ ë°›ê³  ìžˆìŠµë‹ˆë‹¤."

    # í‚¤ì›Œë“œ ê¸°ë°˜ ì„¤ëª…
    for keyword, desc in descriptions.items():
        if keyword in theme_name:
            base_desc = desc
            break

    # ë‰´ìŠ¤ì™€ ë“±ë½ë¥  ì •ë³´ ì¶”ê°€
    if news_count and news_count > 0:
        base_desc += f" ìµœê·¼ {news_count}ê±´ì˜ ê´€ë ¨ ë‰´ìŠ¤ê°€ ë³´ë„ë˜ì—ˆìœ¼ë©°, "
    else:
        base_desc += " "

    if "+" in str(change_rate):
        base_desc += f"í‰ê·  {change_rate} ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ê³  ìžˆìŠµë‹ˆë‹¤."
    elif "-" in str(change_rate):
        base_desc += f"í‰ê·  {change_rate} ì¡°ì •ì„ ë°›ê³  ìžˆìŠµë‹ˆë‹¤."
    else:
        base_desc += "ë³´í•©ì„¸ë¥¼ ë³´ì´ê³  ìžˆìŠµë‹ˆë‹¤."

    return base_desc


def find_best_category_match(theme_name: str, category_map: Dict) -> Dict:
    """í…Œë§ˆëª…ê³¼ ê°€ìž¥ ìœ ì‚¬í•œ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°"""
    # ì •í™•ížˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
    if theme_name in category_map:
        return category_map[theme_name]

    # ë¶€ë¶„ ì¼ì¹˜í•˜ëŠ” ê²½ìš° (ê°€ìž¥ ê¸´ ì¼ì¹˜)
    best_match = None
    best_length = 0

    for cat_theme_name, cat_info in category_map.items():
        # ì–‘ë°©í–¥ìœ¼ë¡œ í™•ì¸
        if cat_theme_name in theme_name or theme_name in cat_theme_name:
            match_length = min(len(cat_theme_name), len(theme_name))
            if match_length > best_length:
                best_length = match_length
                best_match = cat_info

    if best_match:
        return best_match

    # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
    return {
        "id": theme_name.lower().replace(" ", "-")[:30],
        "category": "ê¸°íƒ€"
    }


def enrich_weekly_recommendation(input_file: Path, output_file: Path):
    """Weekly Recommendation JSON ë³´ê°•"""
    logger.info("=" * 60)
    logger.info(f"ë°ì´í„° ë³´ê°• ì‹œìž‘: {input_file.name}")
    logger.info("=" * 60)

    # 1. ì›ë³¸ ë°ì´í„° ë¡œë“œ
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # 2. í…Œë§ˆ ì¹´í…Œê³ ë¦¬ ë¡œë“œ
    category_map = load_theme_categories()

    # 3. Hot Themes ì¤‘ë³µ ì œê±°
    seen_themes = set()
    unique_themes = []

    for theme in data.get("hot_themes", []):
        theme_name = theme.get("name", "")
        if theme_name and theme_name not in seen_themes:
            seen_themes.add(theme_name)
            unique_themes.append(theme)

    logger.info(f"ì¤‘ë³µ ì œê±°: {len(data.get('hot_themes', []))}ê°œ â†’ {len(unique_themes)}ê°œ")

    # 4. Hot Themes ë³´ê°•
    enriched_themes = []

    for i, theme in enumerate(unique_themes[:30]):  # ìƒìœ„ 30ê°œ
        theme_name = theme.get("name", "")
        logger.info(f"  [{i+1}/30] í…Œë§ˆ ë³´ê°•: {theme_name}")

        # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­
        cat_info = find_best_category_match(theme_name, category_map)

        # ë“±ë½ë¥  íŒŒì‹±
        change_rate_str = str(theme.get("change_rate", "0%"))
        try:
            change_percent = float(change_rate_str.replace("%", "").replace("+", "").strip())
        except:
            change_percent = 0.0

        # ì ìˆ˜
        score = theme.get("score", 0)

        # ë³´ê°•ëœ í…Œë§ˆ ë°ì´í„°
        enriched_theme = {
            "id": cat_info["id"],
            "name": theme_name,
            "rank": i + 1,
            "score": score,
            "previousScore": max(0, score - 10),  # ìž„ì‹œ: ì´ì „ ì ìˆ˜ëŠ” -10
            "changePercent": change_percent,
            "trend": "up" if change_percent > 0 else ("down" if change_percent < 0 else "stable"),
            "category": cat_info["category"],
            "description": generate_theme_description(
                theme_name,
                theme.get("news_count"),
                change_rate_str
            ),
        }

        # ê´€ë ¨ì£¼ ìˆ˜ ê³„ì‚°
        tier1_stocks = theme.get("tier1_stocks", [])
        tier2_stocks = theme.get("tier2_stocks", [])
        tier3_stocks = theme.get("tier3_stocks", [])

        enriched_theme["relatedStockCount"] = len(tier1_stocks) + len(tier2_stocks) + len(tier3_stocks)

        # Top ì¢…ëª© (tier1ì—ì„œ 3ê°œ)
        top_stock_names = [s.get("name", "") for s in tier1_stocks[:3] if s.get("name")]
        enriched_theme["topStocks"] = top_stock_names

        # ë‰´ìŠ¤ ìˆ˜
        enriched_theme["newsCount"] = theme.get("news_count") or 0

        # í‰ê·  ìˆ˜ìµë¥  (ìž„ì‹œ: ë“±ë½ë¥  ê¸°ë°˜)
        enriched_theme["avgReturn"] = round(change_percent, 2)

        # í‹°ì–´ë³„ ê´€ë ¨ì£¼ ìƒì„¸ ì •ë³´ (ê°„ì†Œí™”)
        enriched_theme["relatedStocks"] = {
            "tier1": [
                {
                    "name": s.get("name", ""),
                    "ticker": s.get("ticker", ""),
                    "changeRate": s.get("change_rate", "0%"),
                    "tier": "1ì°¨",
                    "isPremium": False
                }
                for s in tier1_stocks[:10]  # ìƒìœ„ 10ê°œ
            ],
            "tier2": [
                {
                    "name": s.get("name", ""),
                    "ticker": s.get("ticker", ""),
                    "changeRate": s.get("change_rate", "0%"),
                    "tier": "2ì°¨",
                    "isPremium": False
                }
                for s in tier2_stocks[:10]
            ],
            "tier3": [
                {
                    "name": s.get("name", ""),
                    "ticker": s.get("ticker", ""),
                    "changeRate": s.get("change_rate", "0%"),
                    "tier": "3ì°¨",
                    "isPremium": True  # 3ì°¨ëŠ” í”„ë¦¬ë¯¸ì—„
                }
                for s in tier3_stocks[:10]
            ]
        }

        enriched_themes.append(enriched_theme)

    # 4. ìµœì¢… ë°ì´í„° êµ¬ì„±
    enriched_data = {
        "generated_at": datetime.now().isoformat(),
        "source_file": input_file.name,
        "data_version": "1.0",
        "themes": enriched_themes,
        "weekly_recommendations": data.get("weekly_recommendations", [])[:30],
        "ai_analysis": data.get("ai_recommendations", {}),
        "market_overview": data.get("market_overview", {}),
    }

    # 5. ì €ìž¥
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(enriched_data, f, ensure_ascii=False, indent=2)

    logger.success(f"âœ… ë°ì´í„° ë³´ê°• ì™„ë£Œ: {output_file}")
    logger.info(f"   í…Œë§ˆ: {len(enriched_themes)}ê°œ")
    logger.info(f"   ì¶”ì²œ ì¢…ëª©: {len(enriched_data['weekly_recommendations'])}ê°œ")

    # 6. ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    category_counts = {}
    for theme in enriched_themes:
        cat = theme["category"]
        category_counts[cat] = category_counts.get(cat, 0) + 1

    logger.info("\nðŸ“Š ì¹´í…Œê³ ë¦¬ë³„ í…Œë§ˆ ë¶„í¬:")
    for cat, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):
        logger.info(f"   {cat}: {count}ê°œ")

    return enriched_data


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ìµœì‹  weekly JSON ì°¾ê¸°
    output_dir = Path("output")
    weekly_files = sorted(output_dir.glob("weekly_recommendation_*.json"), reverse=True)

    if not weekly_files:
        logger.error("weekly_recommendation JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        logger.info("ë¨¼ì € python run_weekly_recommendation.py ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
        return

    latest_file = weekly_files[0]

    # ë³´ê°•ëœ ë°ì´í„° ì €ìž¥ ê²½ë¡œ
    enriched_file = output_dir / f"enriched_{latest_file.name}"

    # ë°ì´í„° ë³´ê°• ì‹¤í–‰
    enriched_data = enrich_weekly_recommendation(latest_file, enriched_file)

    logger.success("\n" + "=" * 60)
    logger.success("âœ¨ ëª¨ë“  ë°ì´í„° ë³´ê°• ì™„ë£Œ!")
    logger.success("=" * 60)
    logger.info(f"ì›ë³¸ íŒŒì¼: {latest_file}")
    logger.info(f"ë³´ê°• íŒŒì¼: {enriched_file}")
    logger.info(f"\në‹¤ìŒ ë‹¨ê³„:")
    logger.info(f"  1. API ì„œë²„ ì‹œìž‘: python web_server.py")
    logger.info(f"  2. ë³´ê°•ëœ ë°ì´í„° í™•ì¸: cat {enriched_file}")


if __name__ == "__main__":
    main()
